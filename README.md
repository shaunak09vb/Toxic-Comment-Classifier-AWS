# Toxic-Comment-Classifier-AWS

<p align="center">
  <img height="500" alt="logo" src="https://miro.medium.com/max/1575/0*v8WSU__4_zTAQg-t">
</p>

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GitHub release](https://img.shields.io/github/release/baishalidutta/Comments-Toxicity-Detection?include_prereleases&sort=semver)](https://github.com/shaunak09vb/Toxic-    Comment-Classifier-AWS/releases/)
![Python](https://img.shields.io/badge/python-v3.8.3+-blue.svg)
[![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/shaunak09vb/Toxic-Comment-Classifier-AWS/issues)


## Introduction
Online forums and social media platforms have provided individuals with the means to put forward their thoughts and freely express their opinion on various issues and incidents. In some cases, these online comments contain explicit language which may have an adverse effect on the readers. Comments containing explicit language can be classified into myriad categories such as Toxic, Severe Toxic, Obscene, Threat, Insult, and Identity Hate. The threat of abuse and harassment means that many people stop expressing themselves and give up on seeking different opinions.

To protect users from being exposed to offensive language on online forums or social media sites, companies have started flagging comments and blocking users who are found guilty of using unpleasant language. Several Machine Learning models have been developed and deployed to filter out the unruly language and protect internet users from becoming victims of online harassment and cyberbullying.

## Requirements

- Matplotlib>=3.3.3
- Keras>=2.4.3
- Gradio>=1.5.3
- Scipy==1.5.4
- Numpy>=1.19.5
- Pandas~=1.2.1
- Scikit-learn~=0.24.1
- Nltk~=3.5
- Spacy~=3.0.3
- Tensorflow~=2.4.1

## Installation

* Clone the repository 

`https://github.com/shaunak09vb/Toxic-Comment-Classifier-AWS.git`

* Install the required libraries

`pip3 install -r requirements.txt`

## Blog Link

If you wish discover in detail, the steps taken by me for the implementation of the project. You can read my blog on <a href='https://towardsdatascience.com/toxic-comment-classification-using-lstm-and-lstm-cnn-db945d6b7986'>Medium</a>.

## License [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This project is licensed under MIT License
